---
title:           first pass
author:          Dennis Wollersheim
date:            12.03.2020
linkcolor:       cyan
citecolor:       grey
output:
  pdf_document:
    highlight:   zenburn
---

\tableofcontents

```{r load_data}

library(zoo)
library(tidyverse)
library(readxl)
library(janitor)
library(forecast)
library(seismicRoll)
library(pracma)
library(kableExtra)

read_excel('data/P0150_S1-3_combined.xlsx', sheet=3) %>%
  clean_names() %>%
  select(-starts_with('x')) %>%
  dplyr::rename( raw_current = raw_current_n_a) %>%
  filter( unix_time >   1567123503  & raw_current > 0 ) %>%
  { . } -> df_in





chunkify = function( condition ) {
  # group conditions according to their contigious groups

  condition %>%
    rle() %>%
    pluck('lengths') %>%
    rep(seq_along(.), . )
}


```



```{r initial_smoothing}

smoothing_window_width = 500
inflection_window_width = 10
df_in %>%
  mutate( row_n = row_number()) %>%
  mutate(raw_current = ifelse( row_n %in% 
    findOutliers(df_in$raw_current, n = smoothing_window_width, selectivity = NA, thresholdMin=1, fixedThreshold = TRUE)
,
                              NA, raw_current)) %>%
  mutate( raw_current = na.approx( raw_current)) %>%
  mutate( smoothed = loess( raw_current ~ unix_time, data=., span=.2 ) %>% predict() )  %>%
  mutate( mean_left  = lag(rollapply(smoothed, inflection_window_width, mean, align = "right", fill=NA))) %>%
  mutate( mean_right  = lag(rollapply(smoothed, inflection_window_width, mean, align = "left", fill=NA))) %>%
  mutate( is_max_pt =  replace_na( smoothed > mean_left & smoothed > mean_right, FALSE)) %>%
  mutate( is_min_pt =  replace_na( smoothed < mean_left & smoothed < mean_right, FALSE)) %>% 
  { . } -> df_in_smoothed

```
# smoothed_data

```{r smoothed_data}

df_in_smoothed %>%
  ggplot(aes( unix_time, raw_current  )) +
  geom_line( color='orange') +
  geom_point( color='black', size=.1) +
  geom_line( aes( unix_time, smoothed ), color='green') 


```
#  calculating important points

```{r calculating_important_points}

df_in_smoothed %>%
  mutate( c=chunkify( is_min_pt )) %>%
  filter( c==2 ) %>%
  summarise( min_location = floor(mean( row_n)), min_raw_current = min(raw_current)) %>%
  { . } -> df_min_location

min_location = df_min_location$min_location
min_raw_current = df_min_location$min_raw_current

df_in_smoothed %>%
  mutate( c = chunkify( is_max_pt )) %>%
  filter( c==2) %>%
  summarise( max_location = floor(mean( row_n))) %>%
  pluck('max_location') %>% 
  { . } -> max_location

df_in_smoothed %>%
  mutate( is_2nd_min = 
         (row_n > max_location ) &
         (raw_current < min_raw_current ) ) %>%
  pluck('is_2nd_min') %>%
  rle( ) %>%
  pluck(1,1) %>% 
  { . } -> min_2nd_location
```


# extract out some subset smoothed chunks for fitting predictors

```{r extract_subsets}

df_in_smoothed %>%
  dplyr::filter( row_n < min_location  ) %>%
  mutate(raw_current = tsclean( raw_current)) %>%
  { . } -> df_min

df_in_smoothed %>%
  dplyr::filter( row_n  >= min_location  ) %>%
  dplyr::filter( row_n  <=max_location  ) %>%
  mutate(raw_current = tsclean( raw_current)) %>%
  { . } -> df_max

df_in_smoothed %>%
  dplyr::filter( row_n  >= max_location  ) %>%
  mutate(raw_current = tsclean( raw_current)) %>%
  { . } -> df_end


fit_min = lm( raw_current ~ unix_time, data=df_min)
fit_max = lm( raw_current ~ unix_time, data=df_max)
fit_end = lm( raw_current ~ unix_time, data=df_end)
```
# calculate overall graph parameters to use when generating the new lines

```{r calc_parms}

df_in_smoothed %>%
  summarise( min_ts = min(unix_time),
            max_ts = max( unix_time ),
            n = n(),
            range = max_ts - min_ts,
            step = range / n,
            ) %>%
  { . } -> df_parm

steps_extra = 4000

```
# generate the steps along the unix_time scale to generate the new lines

```{r calc_steps  }

df_steps_before = tibble( unix_time = df_parm$min_ts - seq( 1:steps_extra ) * df_parm$step,
                row_n = 1- 1:steps_extra 
)

df_steps_after = tibble( unix_time = df_parm$max_ts + seq( 1:steps_extra ) * df_parm$step,
                   row_n = df_parm$n+ 1:steps_extra 
)


df_in_smoothed %>%
  select( unix_time, row_n) %>%
  rbind( df_steps_before) %>%
  rbind( df_steps_after) %>%
  arrange( row_n ) %>% 
  { . } -> df_steps



```
# predict in the 3 predicted sections, for all the steps

```{r predict}

df_steps %>%
  mutate( predicted_min = predict( fit_min, .)) %>%
  mutate( predicted_max = predict( fit_max, .)) %>%
  mutate( predicted_end = predict( fit_end, .)) %>%
  { . } -> df_steps

# pull out the AUC size of the triangles

df_steps %>%
  filter( predicted_min > 0 & row_n >= min_location  ) %>% 
  summarise( area = trapz( unix_time, predicted_min) ) %>%
  pluck('area') %>%
  { . } -> area_min_triangle

df_steps %>%
  filter( predicted_max > 0 & row_n <= min_location  ) %>% 
  summarise( area = trapz( unix_time, predicted_max) ) %>%
  pluck('area') %>%
  { . } -> area_max_triangle


df_steps %>%
  filter( predicted_end > 0 ) %>%
  filter( unix_time >= df_parm$max_ts  ) %>% 
  summarise( area = trapz( unix_time, predicted_end) ) %>%
  pluck('area') %>%
  { . } -> area_end_triangle


# the real, raw measurements.  TODO: should smooth this a bit
df_in %>%
  mutate( row_n = row_number()) %>%
  filter( row_n >= min_location  ) %>% 
  summarise( area = trapz( unix_time, raw_current) ) %>%
  pluck('area') %>%
  { . } -> area_uc_full

# the upper bit of the real raw measurement
df_in %>%
  mutate( row_n = row_number()) %>%
  filter( row_n >= min_location  & row_n <= min_2nd_location ) %>% 
  summarise( area = trapz( unix_time, raw_current) ) %>%
  pluck('area') %>%
  { . } -> area_uc_upper

rectangle_area = min_raw_current * 
  (df_in[ min_2nd_location, 'unix_time'] - df_in[ min_location, 'unix_time'] )



df_rv = tibble(
               max_t = area_max_triangle, 
               min_t = area_min_triangle, 
               end_t = area_end_triangle, 
               full_auc = area_uc_full,
               upper_auc = area_uc_upper - rectangle_area
               )



```

# What points were predicted on

```{r plot}

rbind( df_min, df_max ) %>%
  rbind( df_end ) %>%
  ggplot( aes( unix_time, raw_current)) +
    geom_line( color='green' ) +
    geom_point( aes( unix_time, raw_current), data= . %>% filter( is_min_pt), color='red') +
    geom_point( aes( unix_time, raw_current), data= . %>% filter( is_max_pt), color='orange') +
  #  geom_line( aes( unix_time, mean_left ), color='red') +
  geom_line( aes( unix_time, predicted_min), data=(df_steps %>% filter( predicted_min > 0 & row_n > 0  ) )) +
  geom_line( aes( unix_time, predicted_max), data=(df_steps %>% filter( predicted_max > 0 & row_n < max_location ) )) +
  geom_line( aes( unix_time, predicted_end), data=(df_steps %>% filter( predicted_end > 0 & row_n > max_location ) ))

```

# Predicted Areas

There are 5 calculated areas.  Three are predicted triangular chunks  (max, min, and end) and two are measured AUC's: full and upper

 - max - line from max point, through first minimum.  Triangel area is from first minimum to xaxis
 - min - line from start through first minimum.  Triangle area is from first min to xaxis
 - end - line from max through end.  Triangle area is from end to xaxis.
 - full - AUC from first min to end 
 - upper - AUC from first min, to the place where that min appears after the maximum, subtracting the rectangle under that chunk


The numbers you want are:

 - full
 - full - min  (+end?)
 - full+ max (+end?)
 - full + end
 - upper

```{r table}


df_rv %>%
   kable(format.args = list(big.mark = ",") ) %>%
  kable_styling(full_width = T) 


```



