---
title:           Summary For Single Sheet
author:          Dennis Wollersheim
date:            12.03.2020
linkcolor:       cyan
citecolor:       grey
output:
      html_document:
        code_folding: hide
params:
  xls_input_file: data/P/P0152_S1-3_combined.xlsx
  sheet: 3
  sheet_n: 1
  base_file: P0150_S1-3_combined
  start_timestamp: 1568161865
---



```{r initialise,  include=FALSE}

library(zoo)
library(tidyverse)
library(readxl)
library(janitor)
library(forecast)
library(seismicRoll)
library(pracma)
library(kableExtra)
library(magrittr)
library(glue)

try( rm( params ))

# if( !exists( 'params' )) {
  # try({
    # params = tibble(
    # xls_input_file= 'data/P/P0152_S1-3_combined.xlsx',
    # sheet= 'test',
    # sheet_n= 1,
    # base_file= 'test',
    # start_timestamp= 1568161865)
  # }, silent=TRUE )
# }
if( !exists( 'params' )) {
  try({
    params = tibble(
                    xls_input_file= 'data/P/P0049_S2,3_combined.xlsx',
                    sheet= 'P0049_S2_left',
                    sheet_n= 1,
                    base_file= 'test',
                    start_timestamp= 1566433500)
  }, silent=TRUE )
}



header = glue::glue( '# FILE: {params$base_file} SHEET: {params$sheet}  SHEET_N: {params$sheet_n}')

output_csv = glue::glue( 'data/output/{ params$base_file }_sheet_{params$sheet}.csv')

read_excel(params$xls_input_file, sheet=params$sheet_n) %>%
  clean_names() %>%
  select(-starts_with('x')) %>%
  dplyr::rename( raw_current = raw_current_n_a) %>%
  filter( unix_time > params$start_timestamp  & raw_current > 10 & raw_current <1000 ) %>%
  mutate( row_n = row_number()) %>%
  { . } -> df_in


chunkify = function( condition ) {
  # group conditions according to their contigious groups

  condition %>%
    rle() %>%
    pluck('lengths') %>%
    rep(seq_along(.), . )
}


```

`r header`

## replace outliers with mean of neigbouring points

```{r }

smoothing_window_width = 500
inflection_window_width = 50
df_in %>%
  mutate(rc_pruned = ifelse( row_n %in%
    findOutliers(df_in$raw_current, n = smoothing_window_width, selectivity = NA, thresholdMin=1, fixedThreshold = TRUE)
,
                              NA, raw_current)) %>%
  mutate( rc_pruned = na.approx( rc_pruned)) %>%
  mutate( rc_loess = loess( rc_pruned ~ unix_time, data=., span=.2 ) %>% predict() )  %>%
  mutate( mean_left  = lag(rollapply(rc_loess, inflection_window_width, mean, align = "right", fill=NA))) %>%
  mutate( mean_right  = lag(rollapply(rc_loess, inflection_window_width, mean, align = "left", fill=NA))) %>%
  mutate( is_max_pt =  replace_na( rc_loess > mean_left & rc_loess > mean_right, FALSE)) %>%
  mutate( is_min_pt =  replace_na( rc_loess < mean_left & rc_loess < mean_right, FALSE)) %>%
  { . } -> df_in_smoothed

```
## raw input data

```{r }

df_in %>%
  ggplot(aes( unix_time, raw_current  )) +
  geom_line( color='orange') +
  geom_point( color='black', size=.1)

```

## smoothed data

```{r}

df_in_smoothed %>%
  ggplot(aes( unix_time, rc_pruned  )) +
  geom_line( color='orange') +
  geom_point( color='black', size=.1) +
  geom_line( aes( unix_time, rc_loess ), color='green')


```

## smoothed data with additional cleaning

TODO: Kelly, choose one of these 4 cleaning methods to calculate your AUC values.  Currently using the first, no cleaning whatsoever

```{r}

df_in_smoothed %>%
  mutate(rc_pruned = tsclean( rc_pruned)) %>%
  ggplot(aes( unix_time, rc_pruned  )) +
  geom_line( color='orange') +
  geom_point( color='black', size=.1)


```

##  calculating important points
 - first min,
 - first max after first min,
 - location of first min after previous max

```{r}

df_in_smoothed %>%
  mutate( c=chunkify( is_min_pt )) %>%
  filter( c==2 ) %>%
  summarise( min_location = floor(mean( row_n)), min_raw_current = min(rc_pruned)) %>%
  { . } -> tuple_min_location

min_location = tuple_min_location$min_location
min_raw_current = tuple_min_location$min_raw_current

# caculate the last location, and the last raw_current
last_location = length( df_in_smoothed)
last_raw_current = df_in_smoothed %>% pluck('rc_pruned', last_location )




df_in_smoothed %>%
  filter( row_n > min_location ) %>%
  mutate( c = chunkify( is_max_pt )) %>%
  filter( c==2) %>%
  summarise( max_location = floor(mean( row_n))) %>%
  pluck('max_location') %>%
  { . } -> max_location

df_in_smoothed %>%
  mutate( is_2nd_min =
         (row_n > max_location ) &
         (rc_pruned < min_raw_current ) ) %>%
  pluck('is_2nd_min') %>%
  rle( ) %>%
  pluck(1,1) %>%
  { . } -> min_2nd_location


```


## extract out some subset smoothed chunks for fitting prediction lines

```{r}

df_in_smoothed %>%
  dplyr::filter( row_n < min_location  ) %>%
  mutate(rc_pruned = tsclean( rc_pruned)) %>%
  { . } -> df_min

df_in_smoothed %>%
  dplyr::filter( row_n  >= min_location  ) %>%
  dplyr::filter( row_n  <=max_location  ) %>%
  mutate(rc_pruned = tsclean( rc_pruned)) %>%
  { . } -> df_max

df_in_smoothed %>%
  dplyr::filter( row_n  >= max_location  ) %>%
  mutate(rc_pruned = tsclean( rc_pruned)) %>%
  { . } -> df_end

df_in_smoothed %>%
  dplyr::filter( row_n  >= min_location  ) %>%
  mutate(rc_pruned = tsclean( rc_pruned)) %>%
  { . } -> df_parabola

df_parabola %>%
  filter( row_n > max_location  ) %>%
  filter( rc_pruned == min( rc_pruned)) %>%
  filter( row_n == min( row_n)) %>%
  bind_rows( df_parabola %>% filter( row_n == min( row_n)) ) %>%
  arrange(row_n ) %>%
  { . } -> df_parabola_endpoints


fit_min = lm( rc_pruned ~ unix_time, data=df_min)
fit_max = lm( rc_pruned ~ unix_time, data=df_max)
fit_end = lm( rc_pruned ~ unix_time, data=df_end)
fit_parabola_base = lm( rc_pruned ~ unix_time, data=df_parabola_endpoints)

```
## calculate overall graph parameters to use when generating the new lines

```{r}

df_in %>%
  summarise( min_ts = min(unix_time),
            max_ts = max( unix_time ),
            n = n(),
            range = max_ts - min_ts,
            step = range / n,
            ) %>%
  { . } -> df_parm


```
## generate the steps along the unix_time scale to generate the new lines

```{r}

steps_extra = 8000

df_steps_before = tibble( unix_time = df_parm$min_ts - seq( 1:steps_extra ) * df_parm$step,
                row_n = 1- 1:steps_extra
)

df_steps_after = tibble( unix_time = df_parm$max_ts + seq( 1:steps_extra ) * df_parm$step,
                   row_n = df_parm$n+ 1:steps_extra
)

df_in_smoothed %>%
  select( unix_time, row_n) %>%
  rbind( df_steps_before) %>%
  rbind( df_steps_after) %>%
  arrange( row_n ) %>%
  { . } -> df_steps



```
## predict the area of the three predicted sections

```{r}

df_steps %>%
  mutate( predicted_min = predict( fit_min, .)) %>%
  mutate( predicted_max = predict( fit_max, .)) %>%
  mutate( predicted_end = predict( fit_end, .)) %>%
  mutate( predicted_parabola_base = predict( fit_parabola_base, .)) %>%
  { . } -> df_steps


# need to figure out where parabola_base stops (minimum of end, or where it intersects actual)

df_in_smoothed %>%
  inner_join( df_steps, by=c('unix_time', 'row_n')) %>%
  arrange( row_n ) %>%
  filter( row_n > max_location & predicted_parabola_base >= rc_pruned ) %>%
  filter( row_n == min( row_n )) %>%
  pluck( 'row_n' ) %>% 
  { . } -> predicted_parabola_base_end


# pull out the AUC size of the triangles

df_steps %>%
  filter( predicted_min > 0 & row_n >= min_location  ) %>%
  summarise( area = trapz( unix_time, predicted_min) ) %>%
  pluck('area') %>%
  { . } -> area_min_triangle

df_steps %>%
  filter( predicted_max > 0 & row_n <= min_location  ) %>%
  summarise( area = trapz( unix_time, predicted_max) ) %>%
  pluck('area') %>%
  { . } -> area_max_triangle


df_steps %>%
  filter( predicted_end > 0 ) %>%
  filter( unix_time >= df_parm$max_ts  ) %>%
  summarise( area = trapz( unix_time, predicted_end) ) %>%
  pluck('area') %>%
  { . } -> area_end_triangle



```
## calculate the AUC for the raw / smoothed data

```{r}

# the real, raw measurements.  TODO: should smooth this a bit
df_in %>%
  filter( row_n >= min_location  ) %>%
  summarise( area = trapz( unix_time, raw_current) ) %>%
  pluck('area') %>%
  { . } -> area_uc_full_raw

# AUC for smoothed data
df_in_smoothed %>%
  filter( row_n >= min_location  ) %>%
  summarise( area = trapz( unix_time, rc_pruned) ) %>%
  pluck('area') %>%
  { . } -> area_uc_full_smoothed

# AUC for smoothed data loess
df_in_smoothed %>%
  filter( row_n >= min_location  ) %>%
  summarise( area = trapz( unix_time, rc_loess) ) %>%
  pluck('area') %>%
  { . } -> area_uc_full_loess

# AUC for smoothed data cleaned
df_in_smoothed %>%
  filter( row_n >= min_location  ) %>%
  mutate( rc_pruned = tsclean( rc_pruned)) %>%
  summarise( area = trapz( unix_time, rc_pruned) ) %>%
  pluck('area') %>%
  { . } -> area_uc_full_cleaned

# the upper bit of the real raw measurement
df_in_smoothed %>%
  filter( row_n >= min_location  & row_n <= min_2nd_location ) %>%
  summarise( area = trapz( unix_time, rc_pruned) ) %>%
  pluck('area') %>%
  { . } -> area_uc_upper

# to get upper bit, need to subtract the rectangle below
# calculate rectangle height by width
library(magrittr)
df_in_smoothed[ min_2nd_location, 'unix_time'] %>%
  subtract( df_in[ min_location, 'unix_time'] ) %>%
  multiply_by(  min_raw_current  ) %>%
  unlist() %>%
  { . } -> rectangle_area


# the upper bit above the parabola base
df_in_smoothed %>%
  filter( row_n >= min_location & row_n <= predicted_parabola_base_end  ) %>%
  summarise( area = trapz( unix_time, rc_pruned) ) %>%
  pluck('area') %>%
  { . } -> area_uc_parabola

df_steps %>%
  filter( row_n >= min_location & row_n <= predicted_parabola_base_end  ) %>%
  summarise( area = trapz( unix_time, predicted_parabola_base) ) %>%
  pluck('area') %>%
  { . } -> area_uc_parabola_base

df_auc = tibble(
                raw = area_uc_full_raw,
                smoothed = area_uc_full_smoothed,
                loess = area_uc_full_loess,
                smoothed_and_cleaned = area_uc_full_cleaned
                  )



df_rv = tibble(
               max_t = area_max_triangle,
               min_t = area_min_triangle,
               end_t = area_end_triangle,
               full_auc = area_uc_full_raw,
               upper_auc = area_uc_upper - rectangle_area,
               parabola_auc = area_uc_parabola- area_uc_parabola_base
               )



```

## What points were predicted on

```{r}

rbind( df_min, df_max ) %>%
  rbind( df_end ) %>%
  ggplot( aes( unix_time, rc_pruned)) +
    geom_line( color='green' ) +
    geom_point( aes( unix_time, rc_pruned), data= . %>% filter( is_min_pt), color='red') +
    geom_point( aes( unix_time, rc_pruned), data= . %>% filter( is_max_pt), color='orange') +
  #  geom_line( aes( unix_time, mean_left ), color='red') +
  geom_line( aes( unix_time, predicted_min), data=(df_steps %>% filter( predicted_min > 0 & row_n > 0  ) )) +
  geom_line( aes( unix_time, predicted_max), data=(df_steps %>% filter( predicted_max > 0 & row_n < max_location ) )) +
  geom_line( aes( unix_time, predicted_end), data=(df_steps %>% filter( predicted_end > 0 & row_n > max_location ) )) +
  geom_line( aes( unix_time, predicted_parabola_base), data=(df_steps %>% filter( row_n > min_location & row_n < predicted_parabola_base_end ) ))

```

## Predicted Areas for the different parts of the graph

There are 5 calculated areas.  Three are predicted triangular chunks  (max, min, and end) and two are measured AUC's: full and upper

 - max - line from max point, through first minimum.  Triangel area is from first minimum to xaxis
 - min - line from start through first minimum.  Triangle area is from first min to xaxis
 - end - line from max through end.  Triangle area is from end to xaxis.
 - full - AUC from first min to end
 - upper - AUC from first min, to the place where that min appears after the maximum, subtracting the rectangle under that chunk


The numbers you want are:

 - full
 - full - min  (+end?)
 - full+ max (+end?)
 - full + end
 - upper

```{r}


df_rv %>%
  kable(format.args = list(big.mark = ",") ) %>%
  kable_styling(full_width = T)


```

## Comparision of AUC for the different smoothing methods

The numbers you want are:

```{r}

df_auc %>%
  kable(format.args = list(big.mark = ",") ) %>%
  kable_styling(full_width = T)

tibble( base_file=params$base_file, sheet_n=params$sheet_n) %>%
  bind_cols( df_rv ) %>%
  bind_cols( df_auc ) %>%
  write_csv( output_csv )

```



